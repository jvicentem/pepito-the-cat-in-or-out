{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi! The purpose of this project is to detect when Pépito (https://twitter.com/PepitoTheCat) is leaving or when Pépito is back at home."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've downloaded all the images posted from his Twitter account (up to this date: 2018/06/06). There are 10,041 images plus another 227 images that I'm not gonna use since they have a different resolution (I want to keep this simple, at least for now that I'm starting). I'm not uploading the images to the GitHub repo, but if you want them ask me and I'll find a way to publish them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specially check for how unbalanced classes are\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_images = pd.read_csv('./data/labeled_images.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>home</th>\n",
       "      <td>5762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out</th>\n",
       "      <td>4279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       img_name\n",
       "label          \n",
       "home       5762\n",
       "out        4279"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_count = labelled_images.groupby('label').count()[['img_name']]\n",
    "label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prct home labels: 57.282\n"
     ]
    }
   ],
   "source": [
    "print('prct home labels: %.3f' % ( (5762 / (5762+4297)) * 100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prct home labels: 42.539\n"
     ]
    }
   ],
   "source": [
    "print('prct home labels: %.3f' % ( (4279 / (5762+4297)) * 100) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes are not too unbalanced. But I think this shows possible bot problems, because it means there are consecutive classes and that shouldn't be possible because if Pépito leaves there's no way he can leave home again, he must have gotten back home before. Anyway, I'm sure there are other reason I don't know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "labelled_images = shuffle(labelled_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/anaconda3/envs/intro/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_x = labelled_images[['img_name']]\n",
    "data_y = labelled_images[['label']]\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, train_size=0.8, random_state=16121993, stratify = data_y.get_values())\n",
    "dev_x, test_x, dev_y, test_y = train_test_split(test_x, test_y, train_size=0.5, random_state=16121993, stratify = test_y)\n",
    "train_x, train_dev_x, train_y, train_dev_y = train_test_split(train_x, train_y, train_size=0.9, random_state=16121993, stratify = train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After thinking about this, I'm gonna mix day and night pics and see how the model works. In case it doesn't work (among many other things) it would be worth it to pay more attention to this and make the train and dev splits to be as similar as possible.\n",
    "\n",
    "I assume (I haven't checked every picture, sorry) the camera is fixed and its angle doesn't change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create images train/train-dev/dev/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import auto_labelling\n",
    "# import os, errno\n",
    "# from shutil import copyfile\n",
    "# import logging\n",
    "\n",
    "# def create_folder(path):\n",
    "#     try:\n",
    "#         os.makedirs(path)\n",
    "#     except OSError as e:\n",
    "#         if e.errno != errno.EEXIST:\n",
    "#             raise        \n",
    "\n",
    "# def create_folder_structures(folder_name, data_x, data_y):\n",
    "#     data = pd.concat([data_x, data_y], axis=1)\n",
    "    \n",
    "#     folder_name_full_path = os.path.join(auto_labelling.FILES_FOLDER_PATH, folder_name)\n",
    "    \n",
    "#     create_folder(folder_name_full_path)\n",
    "    \n",
    "#     home_imgs_full_path = os.path.join(folder_name_full_path, 'home')\n",
    "#     out_imgs_full_path = os.path.join(folder_name_full_path, 'out')\n",
    "    \n",
    "#     create_folder(home_imgs_full_path)\n",
    "#     create_folder(out_imgs_full_path)\n",
    "    \n",
    "#     logger = logging.getLogger('info_logger')\n",
    "#     logger.setLevel(logging.INFO)\n",
    "    \n",
    "#     for row in data.itertuples(index=True):      \n",
    "#         file_full_path = os.path.join(auto_labelling.FILES_FOLDER_PATH, getattr(row, 'img_name'))\n",
    "        \n",
    "#         if os.path.isfile(file_full_path): \n",
    "#             if getattr(row, 'label') == 'home':            \n",
    "#                 copyfile(file_full_path, os.path.join(home_imgs_full_path, getattr(row, 'img_name')))\n",
    "#             elif getattr(row, 'label') == 'out':\n",
    "#                 copyfile(file_full_path, os.path.join(out_imgs_full_path, getattr(row, 'img_name')))          \n",
    "#         else:\n",
    "#             logger.info('%s is an old pic and it won\\'t be used' % getattr(row, 'img_name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder_name = 'train'\n",
    "train_dev_folder_name = 'train_dev'\n",
    "dev_folder_name = 'dev'\n",
    "test_folder_name = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_folder_structures(train_folder_name, train_x, train_y)\n",
    "# create_folder_structures(train_dev_folder_name, train_dev_x, train_dev_y)\n",
    "# create_folder_structures(dev_folder_name, dev_x, dev_y)\n",
    "# create_folder_structures(test_folder_name, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/anaconda3/envs/intro/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7223 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import os\n",
    "import auto_labelling\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, data_format = 'channels_first')\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "                    os.path.join(auto_labelling.FILES_FOLDER_PATH, train_folder_name),\n",
    "                    target_size=(640, 480),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    class_mode='binary',\n",
    "                    classes = ['home', 'out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm gonna use Convolutional Neural Networks. I'm gonna start with very easy networks and then try different architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Activation, Input, concatenate, Dropout, Flatten, LeakyReLU, AveragePooling2D, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.initializers import glorot_normal\n",
    "K.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture 1: CNN - HL - output HL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                  width height\n",
    "X_input = Input((3, 640, 480))\n",
    "X = Conv2D(16, (4, 4), strides = (1, 1), padding = 'valid', name = 'conv1', kernel_initializer = glorot_normal(seed=SEED))(X_input)\n",
    "X = BatchNormalization(axis = 1, name = 'bn1')(X)\n",
    "X = Dropout(0.2)(X)\n",
    "X = LeakyReLU(alpha=0.3)(X)\n",
    "X = AveragePooling2D(pool_size=(4, 4), strides=None, padding='valid')(X)\n",
    "\n",
    "X = Flatten()(X)\n",
    "X = Dense(1, activation='sigmoid', name='output_layer', kernel_initializer = glorot_normal(seed=SEED))(X)\n",
    "\n",
    "\n",
    "model = Model(inputs = X_input, outputs = X, name='Model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3, 640, 480)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 16, 637, 477)      784       \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 16, 637, 477)      64        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 637, 477)      0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 637, 477)      0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 16, 159, 119)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 302736)            0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 302737    \n",
      "=================================================================\n",
      "Total params: 303,585\n",
      "Trainable params: 303,553\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#                batch_size specified at train_generator\n",
    "(model.fit_generator(train_generator, steps_per_epoch = np.floor(len(train_x) / BATCH_SIZE), \n",
    "                     epochs = 1, workers = 4, verbose = 2,\n",
    "                     max_queue_size = 16,\n",
    "                     use_multiprocessing = True\n",
    "                    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [intro]",
   "language": "python",
   "name": "Python [intro]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
